{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69bfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6104f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Load and Parse FASTA File ------------------\n",
    "def load_fasta(file_path):\n",
    "    sequences = []\n",
    "    current_seq = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if current_seq:\n",
    "                    sequences.append(''.join(current_seq))\n",
    "                    current_seq = []\n",
    "            else:\n",
    "                current_seq.append(line)\n",
    "        if current_seq:\n",
    "            sequences.append(''.join(current_seq))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sequences\n",
    "fasta_path = \"uniprot_sprot.fasta\"\n",
    "sequences = load_fasta(fasta_path)\n",
    "\n",
    "# Optional filtering\n",
    "sequences = [s for s in sequences if 30 < len(s) < 300]\n",
    "\n",
    "# ------------------ Character Mapping ------------------\n",
    "all_chars = sorted(list(set(''.join(sequences))))\n",
    "char_to_idx = {c: i + 1 for i, c in enumerate(all_chars)}  # 0 reserved for padding\n",
    "idx_to_char = {i + 1: c for i, c in enumerate(all_chars)}\n",
    "vocab_size = len(char_to_idx) + 1  # +1 for padding (0)\n",
    "\n",
    "# ------------------ Prepare Input and Target ------------------\n",
    "seq_length = 50\n",
    "X, y = [], []\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(0, len(seq) - seq_length):\n",
    "        input_seq = seq[i:i + seq_length]\n",
    "        target_char = seq[i + seq_length]\n",
    "        X.append([char_to_idx[c] for c in input_seq])\n",
    "        y.append(char_to_idx[target_char])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Model Definition or Loading ------------------\n",
    "model_path = \"protein_generator_model.h5\"\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading existing model...\")\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    print(\"Training new model...\")\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=64, input_length=seq_length),\n",
    "        LSTM(256),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # ------------------ Training ------------------\n",
    "    model.fit(X, y, batch_size=128, epochs=10)\n",
    "    model.save(model_path)\n",
    "\n",
    "# ------------------ Sequence Generation Function ------------------\n",
    "def generate_sequence(seed, length=100, temperature=1.0):\n",
    "    result = seed\n",
    "    for _ in range(length):\n",
    "        input_seq = [char_to_idx.get(c, 0) for c in result[-seq_length:]]\n",
    "        input_seq = pad_sequences([input_seq], maxlen=seq_length)\n",
    "        pred = model.predict(input_seq, verbose=0)[0]\n",
    "\n",
    "        # Apply temperature for diversity\n",
    "        pred = np.log(pred + 1e-8) / temperature\n",
    "        pred = np.exp(pred) / np.sum(np.exp(pred))\n",
    "\n",
    "        next_idx = np.random.choice(range(vocab_size), p=pred)\n",
    "        next_char = idx_to_char.get(next_idx, '')\n",
    "        result += next_char\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Generate and Print ------------------\n",
    "seed_seq = sequences[0][:seq_length]\n",
    "new_protein = generate_sequence(seed_seq, length=150, temperature=0.8)\n",
    "print(\"Generated Protein Sequence:\\n\", new_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778e026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57b616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa3b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea7919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34a4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d15799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a77b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc776a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89000a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f5cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
